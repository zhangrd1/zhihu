目标人群：美术、客户端或初级TA
方式：简明、宏观、系统
阅读时长：20min（）

# 01引言
- 最近开始从UE接触Unity，用一个mini项目为契机，入门了一下Unity编辑器的一些操作方式和Unity引擎的基本概念，正好最近项目接近结束，记录一下作为近期的学习成果
- 想来想去以渲染架构为主题，因为是游戏引擎的基本也是最重要的概念
- 在中外互联网检索了一下，分别聊UE和Unity的很多，但二者在一起聊的比较少，但可能无法，对比研究是很有用的。正好以Unity和UE（Unreal Engine）的渲染架构作介绍，并进行对比来明确二者的一些区别。
- 文章特点：不会深入技术细节，而是宏观上对二者进行一些区分有一些初步概念；

# 02引擎面临的共性问题
所处的时间、空间相同，面临的问题是一致的，方案只有差异没有优劣，只有取舍。所以在聊方案之前，聊聊面临的共性问题是很有必要的：
- 渲染质量与性能：在视觉效果和实时渲染性能之间找到平衡
- 多平台兼容：从移动设备到高端PC
![[Pasted image 20240820230532.png]]

- 目标客户：广泛的开发者群体，从独立开发者到AAA级工作室，能力不同

而接下来所讨论的，Unity和UE是如何针对这些问题，做出了不同的会赢。

# 03Unity渲染架构的原则与方案
虽然还没开始讨论，但刻板印象总是认为Unity注重灵活性和性能牺牲质量，而UE追求高画面品质牺牲性能和灵活性。我只只能说，刻板印象可耻但很有用。

Unity的渲染管线高度的灵活性和可定制性。

内置渲染管线、SRP,URP（Universal Render Pipeline）和HDRP（High Definition Render Pipeline）
![[Pasted image 20240820230849.png]]

## 内置管线（Build-in）
Build-in Render Pipeline（下文简称BiRP）是Unity最早期的渲染管线，最大特点是设计简单、开箱即用，适合各种设备，但缺点是高度封装，大部分配置硬编码在C++层中难以灵活修改。

由于BiRP需要支持多种平台和API，因此其架构往往只能提供通用性能，而不能针对特定平台进行最佳化。同时，由于其允许在帧的任意阶段动态注入状态变更，缓存数据的效果变差，增加了性能开销。

BiRP允许用户通过C#回调在帧的任何阶段动态修改渲染状态，但这种灵活性也带来了性能问题。例如，动态切换对象的状态（如从刚体转换为蒙皮动画对象）会导致缓存失效和性能下降。

尽管SRP是更现代化的架构，但由于BiRP在广泛项目中仍然被大量使用，因此Unity依然维持其支持，尤其是在那些已经投入生产的项目中。

- BiRP中渲染算法和流程是固定的，虽然方便用户快速上手，但在一些特定情况下无法充分利用硬件特性，导致通用化的架构难以提供最佳的性能。

## SRP：URP+HDRP
BiRP的问题促使Unity开发了更灵活的可编程渲染管线（Scriptable Render Pipeline，下文简称SRP）架构，让开发者定制渲染流程。

![[Pasted image 20240821094724.png]]

在SRP架构中，Unity渲染的底层仍然由C++编写，负责处理对性能要求极高的操作，尤其是涉及与GPU和图形API（如Vulkan、DirectX）的交互。

而C#主要用于SRP架构中的顶层部分，用户可以在C#层来定义和控制渲染流程，根据具体需求自定义渲染管线。例如，URP（Universal Render Pipeline）和HDRP（High Definition Render Pipeline）的实现都主要基于C#，是Unity官方提供的，分别用于通用渲染和高质量渲染。关于URP和HDRP不是文章主要内容，不再展开，可以单独讨论。

这种设计带来了几个好处：
1. 在C#层处理渲染逻辑，修改渲染管线变得更容易，参数调整和实时效果预览，而不需要重建整个引擎。这种“热重载”特性允许开发者无需重新启动引擎就能看到修改效果
2. 提供了沙盒环境，用户层的代码即使崩溃也不会影响底层引擎。这种设计确保了引擎的稳定性。
3. 



- RnederPass Abstraction
- Game-Logic Rendering Control


We probably need to iterate on the shader passes, render textures layout, etc. The heart and soul of the algorithm – and that’s where we want to spend our time, not the boiler-plate code in the layers below

Though occasionally, when shaders have very specific hardware dependency (VRS, instancing, tessellation, async compute), they need to reach to the engine or low-level API layers and may require deeper changes, in line with the corresponding shader changes. This is an infrequent operation, mostly when bringing up new hardware or API




优势：
- Componentize the steps of rendering via a concepts of building blocks you can put together, customize or extend
- Separate control of rendering order from the high throughput inner loops execution
- moved majority of iterative algorithm development into C# and shaders we can reap all the benefits of quick iteration with hot reload and parameter changes. 



but shaders mostly need to agree just with C# layers (with the exception of high throughput instance data, which is still provided by C++ for performance reasons) which still need low-level exposure as before, for example, all instance data to shaders still comes from the C++ side: Transform matrices, light indices, reflection probe settings, light settings, layer settings, lightmap indices and UV rects, interpolated probe SHs, for faster setup). Table for all hardcoded C++ shader instance data: https://blogs.unity3d.com/wp-content/uploads/2019/02/Screen-Shot-2019-02-27-at- 3.50.52-PM.png





SRP的引入展示了Unity向模块化、定制化方向的转变，反映了其在适应不同项目需求和性能优化上的努力。


这一部分可以更加结构化，依次对比两个引擎在关键渲染模块（如光照系统、材质系统、后处理效果等）上的不同实现方案。这部分不需要太深入技术细节，但可以通过具体例子来体现设计哲学的差异，例如UE的“基于物理的渲染（PBR）”体系与Unity的灵活性之间的权衡。



相比Unity的（SRP），UE并没有像Unity那样提供完全可编程的渲染管线。但这种设计取舍是基于不同的市场需求：

Unity SRP：更适合需要高度定制渲染路径的开发者，特别是在移动平台或特殊需求下，SRP允许开发者从底层设计自己的渲染流程。

UE的统一架构：则更侧重于提供一套开箱即用的高质量渲染管线，且支持在此基础上的插件化扩展。这使得UE在3A游戏和电影制作中占据优势，因为这些场景需要稳定、高质量且一致的渲染表现。

![[Pasted image 20240820233834.png]]
The interface is designed such that you invoke a culling operation on the scene graph followed by a draw on the resultant list of scene nodes - specifying specific shader passes to draw with. Under the hood the engine will cull the scene graph in a jobified way and identify nodes that pass the culling and drawing parameters that are passed into the C++ low-level renderer architecture. Shaders can be designed for a particular render pipeline in mind

## More
![[Pasted image 20240820234259.png]]
#### 资产接口（Asset Interface）
管理与渲染相关的资源和数据。它包括Material、Texture、Mesh、Shader等。这些资源在Unity Editor中创建，并被SRP用作渲染输入。负责将资源数据传递给渲染管线。

值得一提，它支持Unity中BiRP已有的资源类型，迁移到SRP变得相对容易。为了确保向后兼容性和便捷的项目迁移，Unity保留了这些基本的接口设计。这样，开发者在将项目从内置管线迁移到SRP时，只需要重新编写或调整着色器内容，而不必大幅改动项目中已有的材质、纹理或网格数据。

#### SRP前端（SRP Frontend）
控制整个渲染管线逻辑，位于C#脚本层中。SRP前端负责定义渲染流程、控制渲染顺序以及管理渲染过程中的各种状态和参数。URP和HDRP都是基于此前端实现的渲染管线。
- **渲染管线的定义**：SRP Frontend 通过C#脚本定义渲染管线的逻辑，控制如何处理每一帧的渲染，包括光照计算、阴影生成、后处理效果等。Unity提供了两个默认实现：URP (Universal Render Pipeline) 和 HDRP (High Definition Render Pipeline)，开发者也可以自定义SRP。
- **渲染任务的调度**：SRP Frontend根据开发者定义的规则，调度渲染流程中的各个步骤。例如，在延迟渲染路径中，它会先渲染G-buffer，再进行光照计算和后处理。
- **灵活性与可扩展性**：SRP的可编程特性允许开发者为不同的项目需求定制渲染管线，从而在性能、视觉效果和资源使用之间找到最佳平衡。

#### 图形后端（Graphics Backend）
是SRP中的底层实现部分，负责执行高性能的渲染操作。如批处理、剔除、与图形API的交互等一切性能敏感。它以C++实现，并提供高吞吐量和低延迟的渲染路径。SRP的前端通过渲染上下文与图形后端交互，以实现具体的绘制操作。

- **图形API抽象**：Graphics Backend封装了不同平台上的底层图形API，如DirectX、Vulkan、Metal和OpenGL。
- **渲染命令的执行**：在渲染流程中，Graphics Backend负责执行所有低级别的渲染命令，如绘制调用（Draw Call）、状态设置和内存管理。
- **性能优化与兼容性处理**：Graphics Backend在不同平台上进行适配和优化，例如处理多线程渲染、内存管理、资源同步等问题，以确保不同平台下的渲染效率和兼容性。



```c#
// 定义自定义渲染管线资源
class MyRenderPipelineAsset : RenderPipelineAsset {
    protected override RenderPipeline CreatePipeline() {
        return new MyRenderPipeline();
    }
}

// 自定义渲染管线实现
class MyRenderPipeline : RenderPipeline {
    // 主渲染流程
    protected override void Render(ScriptableRenderContext context, Camera[] cameras) {
        // 遍历每个摄像机，渲染它们的内容
        foreach (Camera camera in cameras) {
            // 设置摄像机参数
            SetupCamera(context, camera);
            
            // 执行自定义渲染流程
            RenderCamera(context, camera);
            
            // 提交上下文中的渲染命令
            context.Submit();
        }
    }

    // 设置摄像机参数
    void SetupCamera(ScriptableRenderContext context, Camera camera) {
        // 配置视图矩阵、投影矩阵等
        context.SetupCameraProperties(camera);
    }

    // 渲染摄像机内容
    void RenderCamera(ScriptableRenderContext context, Camera camera) {
        // 1. 执行物体剔除
        CullingResults cullingResults = PerformCulling(camera);
        
        // 2. 开始渲染过程，设置渲染目标等
        CommandBuffer cmd = new CommandBuffer();
        cmd.SetRenderTarget(...);
        
        // 3. 绘制天空盒
        context.DrawSkybox(camera);
        
        // 4. 渲染场景中的物体
        var drawingSettings = new DrawingSettings(...);
        var filteringSettings = new FilteringSettings(...);
        context.DrawRenderers(cullingResults, ref drawingSettings, ref filteringSettings);
        
        // 5. 渲染后处理效果
        ApplyPostProcessing(context, camera);
    }

    // 执行剔除逻辑
    CullingResults PerformCulling(Camera camera) {
        ScriptableCullingParameters cullingParams;
        if (camera.TryGetCullingParameters(out cullingParams)) {
            return context.Cull(ref cullingParams);
        }
        return default;
    }

    // 应用后处理效果
    void ApplyPostProcessing(ScriptableRenderContext context, Camera camera) {
        // 后处理渲染代码，执行诸如Bloom、Color Grading等效果
    }
}

// 在项目中使用自定义渲染管线
[CreateAssetMenu(menuName = "Rendering/My Render Pipeline")]
public class MyRenderPipelineAsset : RenderPipelineAsset {
    protected override RenderPipeline CreatePipeline() {
        return new MyRenderPipeline();
    }
}// 定义自定义渲染管线资源 class MyRenderPipelineAsset : RenderPipelineAsset { protected override RenderPipeline CreatePipeline() { return new MyRenderPipeline(); } } // 自定义渲染管线实现 class MyRenderPipeline : RenderPipeline { // 主渲染流程 protected override void Render(ScriptableRenderContext context, Camera[] cameras) { // 遍历每个摄像机，渲染它们的内容 foreach (Camera camera in cameras) { // 设置摄像机参数 SetupCamera(context, camera); // 执行自定义渲染流程 RenderCamera(context, camera); // 提交上下文中的渲染命令 context.Submit(); } } // 设置摄像机参数 void SetupCamera(ScriptableRenderContext context, Camera camera) { // 配置视图矩阵、投影矩阵等 context.SetupCameraProperties(camera); } // 渲染摄像机内容 void RenderCamera(ScriptableRenderContext context, Camera camera) { // 1. 执行物体剔除 CullingResults cullingResults = PerformCulling(camera); // 2. 开始渲染过程，设置渲染目标等 CommandBuffer cmd = new CommandBuffer(); cmd.SetRenderTarget(...); // 3. 绘制天空盒 context.DrawSkybox(camera); // 4. 渲染场景中的物体 var drawingSettings = new DrawingSettings(...); var filteringSettings = new FilteringSettings(...); context.DrawRenderers(cullingResults, ref drawingSettings, ref filteringSettings); // 5. 渲染后处理效果 ApplyPostProcessing(context, camera); } // 执行剔除逻辑 CullingResults PerformCulling(Camera camera) { ScriptableCullingParameters cullingParams; if (camera.TryGetCullingParameters(out cullingParams)) { return context.Cull(ref cullingParams); } return default; } // 应用后处理效果 void ApplyPostProcessing(ScriptableRenderContext context, Camera camera) { // 后处理渲染代码，执行诸如Bloom、Color Grading等效果 } } // 在项目中使用自定义渲染管线 [CreateAssetMenu(menuName = "Rendering/My Render Pipeline")] public class MyRenderPipelineAsset : RenderPipelineAsset { protected override RenderPipeline CreatePipeline() { return new MyRenderPipeline(); } }
```


LOD (Level of Detail)
在 Graphics Backend 中，LOD 数据不是在渲染时实时计算的，而是在前一阶段的剔除和设置流程中被确定。具体来说：

LOD 的选择：在渲染前，系统会根据摄像机的距离、屏幕空间覆盖率等条件确定要使用哪个 LOD 级别。

Culling (剔除)
剔除操作发生在渲染的早期阶段，直接影响哪些对象会进入渲染管线：

视锥剔除（Frustum Culling）：判断对象是否在摄像机的视野内。
遮挡剔除（Occlusion Culling）：判断对象是否被其他对象遮挡。
剔除的结果直接决定哪些对象的数据会被传递到 GPU 进行渲染。Graphics Backend 根据这些结果来生成优化的渲染指令，避免不必要的绘制调用。

SetupGoData (Setup GameObject Data)
负责准备对象的渲染数据。这涉及将场景图中的信息（如物体的变换、材质配置、光照信息等）转换为 Graphics Backend 能够直接使用的数据格式：

SetupGoData 完成数据准备后，Graphics Backend 可以直接访问和使用这些数据进行渲染。它确保了在渲染过程中，所有对象的数据（例如变换矩阵、材质、光照设置等）都已正确配置。

Renderer (渲染器)
Renderer 是 Unity 场景图和 Graphics Backend 之间的桥梁。负责将对象的网格、材质、光照等信息与渲染管线关联起来。常见的渲染器组件包括MeshRenderer、SkinnedMeshRenderer等。
Renderer 组件会将所有需要渲染的对象信息传递给 Graphics Backend，Graphics Backend 然后将这些对象的资源绑定到渲染流水线上。比如，在批处理中，Renderer 负责确保相同材质的对象被合并在一起，从而减少 Draw Call 的数量。

在Graphics Backend中的实现：
Renderer 会根据场景图中的设置，管理对象的可见性、光照影响、阴影投射等信息。
在渲染过程中，Renderer 组件会根据场景状态自动绑定必要的数据（如网格、材质、实例ID等）到具体的渲染批次中。

在Graphics Backend中的实现：

LOD系统通常在场景图更新和剔除过程中被处理。在这些过程中，Unity根据视图距离和预定义的LOD规则选择合适的模型。
选定的LOD模型数据（例如网格和材质）会作为实例数据传递给渲染管线。这些数据成为渲染过程中需要绑定的资源之一。

Culling用来决定哪些对象需要被渲染。常见的剔除类型包括视锥剔除（Frustum Culling）、遮挡剔除（Occlusion Culling）等。在场景图更新时触发，通过判断物体是否在摄像机的视野内（或是否被其他物体遮挡）。剔除后的可见对象列表会被传递给渲染管线，进入批处理阶段。这些可见对象的数据（如变换矩阵、材质等）会被整理并绑定到具体的渲染指令中。

SetupGoData 用于准备与渲染相关的 GameObject 数据（渲染状态、变换矩阵、材质属性等）。确保在渲染过程中，所有需要的实例数据都已被正确配置和绑定。

5. SRP api
在通过SRP API执行渲染时，必须指定你想要绘制的具体“通道名称”。这就是SRP与着色器渲染之间的连接。

these assets are data types that live in our graphics backend which are then attached to nodes on our scene graph. This means we have access to them at render time. 

资产以引用的方式附加到场景图中的节点上。如MeshRenderer组件会引用一个Mesh和一个或多个Material。材质又会引用具体的着色器（Shader）和与之相关的纹理（Texture）数据。
当场景图被渲染时，渲染管线会遍历这些节点，并根据附加的资产信息生成绘制指令。



由于资产在场景图中是通过引用关联的，这些数据可以在运行时动态更新。多个场景节点可以共享同一个材质或纹理，避免重复加载资源。开发者可以在SRP中自定义数据处理逻辑，扩展或优化渲染管线，而无需修改底层的图形后端实现。

 This is also where our scene graph lives and many of the operations invoked on the SRP API trigger batch processing operations to this scene graph. 



批处理操作是Unity提高渲染性能的重要机制之一。在渲染过程中，多个具有相似属性的对象可以被组合成一个批次进行绘制，从而减少Draw Call的数量。

具体来说，SRP API 调用后，场景图中的节点会根据其渲染属性（如材质、着色器、透明度等）进行分组。例如，所有使用相同材质的对象可以被归为一个批次进行处理。在渲染时，SRP根据这些分组生成批处理指令，发送给图形后端（GPU），从而减少了冗余的状态切换和绘制调用。


在SRP中，以下操作通常会触发对场景图的批处理：
剔除（Culling）：根据摄像机视角，场景图中的节点会被剔除掉不在视野中的对象，只保留需要渲染的节点。
排序（Sorting）：场景图中的节点会按照透明度、深度、材质等属性排序，确保正确的渲染顺序。
合并（Merging）：将共享相同材质和着色器的对象合并到同一批次中。



5. 具体实现：SRP中的场景图处理
在SRP中，开发者可以通过RenderContext和其他API直接与场景图交互，获取需要渲染的节点信息。RenderContext中的剔除和渲染操作会遍历场景图，过滤出有效的渲染对象，并将其组织成批次。例如：

开发者可以通过SRP API调用剔除操作，获取当前视野中的渲染节点。
获取这些节点后，可以根据不同的渲染阶段（如不透明物体、透明物体）将节点分类，生成需要绘制的批次。
这些批处理操作在SRP API层面抽象出来，开发者可以自定义如何组织和处理场景图中的数据，灵活控制渲染流程。



下面是一些在SRP中常用的API及其作用：

1. ScriptableRenderContext
这是SRP的核心类之一，负责与底层渲染管线进行交互，控制渲染过程。通过ScriptableRenderContext，你可以访问和管理场景中的渲染信息，执行各种渲染命令。

常用方法：
DrawRenderers(): 用于绘制场景中的渲染器（Renderers），可根据不同的渲染阶段（如不透明、透明）来过滤和排序对象。
Cull(): 执行剔除操作，返回当前视野中的可见对象列表。
ExecuteCommandBuffer(): 执行命令缓冲区中的渲染命令。
Submit(): 提交所有已添加到上下文中的渲染指令并进行渲染。

2. CommandBuffer
CommandBuffer是一个重要的工具，用于在渲染过程中收集并存储一系列渲染指令，然后批量执行。这有助于优化性能并允许精细控制渲染流程。

常用方法：
SetRenderTarget(): 设置当前渲染目标（如颜色缓冲区、深度缓冲区）。
ClearRenderTarget(): 清除渲染目标的内容。
DrawMesh(): 绘制指定的网格。
Blit(): 将源纹理复制到目标渲染目标，可以用于后处理效果。


4. DrawingSettings
DrawingSettings用于控制如何渲染对象，包括着色器通道的选择、排序规则等。


5. FilteringSettings
FilteringSettings用于定义哪些对象应该被渲染，通常结合DrawingSettings使用。

6. RenderTargetIdentifier
这个类用于标识渲染目标，如颜色缓冲区、深度缓冲区、纹理等。它可以传递给各种渲染方法。

常用场景：

设置和切换不同的渲染目标。
将渲染结果输出到特定的纹理或帧缓冲。

7. RenderPipelineAsset & RenderPipeline
自定义渲染管线的核心，开发者需要继承RenderPipelineAsset和RenderPipeline来创建自己的渲染管线。

常用方法：

Render(): 这是自定义管线的主入口，每一帧都会调用，负责整个渲染流程。
Dispose(): 用于释放资源，当渲染管线被销毁时调用。




3. 渲染上下文（Render Context）
 Context是SRP中连接C#脚本层和C++底层的桥梁。它提供了一组API，使开发者能够从C#层组织和管理渲染任务，如指定需要绘制的对象、定义渲染排序、设置着色器通道等


. We converged on solution that allows for higher level rendering flow to be controlled from c#, but draws to be controlled as batches. Essentially post culling we would have a list of all valid RenderNodes and be able to say: “Render the opaque ones front to back” or “Render the transparent ones back to front”. This allows for rendering control flow to live in c# 

this was called the RenderContext - This is a proxy object that lives within our c++ layer but has a binding layer into c# - Holding this object allows access to our rendering API.

![[Pasted image 20240821002535.png]]
这是上下文中可以进行的操作的粒度



5. 渲染流程（Rendering Workflow）
概述：渲染流程是开发者定义的SRP实际工作流程，包括各个渲染阶段的顺序和逻辑。这一流程由开发者在C#层定制和控制，通常包含以下主要步骤：
剔除（Culling）：决定哪些对象在当前帧中可见。
排序（Sorting）：确定对象的绘制顺序，如不透明物体从前到后绘制、透明物体从后到前绘制。
绘制（Rendering Passes）：执行实际的绘制命令，包括多次渲染通道，如阴影、光照、后处理效果等。
后处理（Post-Processing）：应用如颜色调整、模糊、抗锯齿等效果。


在Unity的渲染架构中，**Render Context**和其他关键概念是理解整个渲染流程的基础。


**ScriptableRenderContext** 提供了渲染命令的上下文，用于在不同的渲染步骤中传递和执行渲染命令。它是SRP中开发者控制渲染流程的接口，主要作用包括：
- **渲染命令的管理**：ScriptableRenderContext允许开发者向渲染队列添加命令，例如绘制几何体、设置相机属性、执行剔除等。
- **控制渲染顺序**：开发者可以通过该上下文精确控制渲染顺序，从而决定哪些物体在什么时候、以什么方式被渲染。
- **支持多Pass渲染**：在一些高级渲染效果中，ScriptableRenderContext能够在不同的渲染Pass之间协调执行，从而实现复杂的效果，例如基于多个渲染目标的合成。

在实际使用中，ScriptableRenderContext常与命令缓冲区（CommandBuffer）配合使用，以便在不同的渲染阶段执行预定义的渲染指令。例如：

csharp

`ScriptableRenderContext context; CommandBuffer cmd = new CommandBuffer(); cmd.SetRenderTarget(...);  // 设置渲染目标 cmd.DrawRenderer(...);     // 执行渲染指令 context.ExecuteCommandBuffer(cmd); context.Submit();          // 提交渲染指令给底层渲染API`



RenderPipeline和RenderPipelineAsset这两个类是SRP的核心结构，用于定义和配置自定义的渲染管线：

- **RenderPipeline**: 该类包含渲染逻辑的具体实现，例如如何遍历摄像机、如何进行剔除、以及在不同渲染阶段如何绘制场景中的对象。RenderPipeline类是所有渲染操作的核心驱动。
- **RenderPipelineAsset**: 这是一个配置类，用于在编辑器中设置渲染管线的资产。开发者可以创建不同的RenderPipelineAsset实例，用于配置不同的渲染需求（如高性能与高画质模式）。


CommandBuffer (命令缓冲区)

**CommandBuffer**是用于记录和执行一系列渲染指令的对象。通过CommandBuffer，开发者可以将多个渲染指令批量提交，以优化渲染效率。它支持在多个渲染Pass之间重用渲染命令，并且能够与ScriptableRenderContext一起实现复杂的渲染流程。

例如，在后处理效果中，CommandBuffer可以用于执行一系列图像处理操作，如模糊、颜色调整、卷积等。



Graphics Backend它接收来自ScriptableRenderContext的渲染命令并将其转换为底层硬件指令。


后处理效果在Unity中被封装为一个Post-Processing Stack，它提供了一整套常见的后处理效果，如Bloom、Anti-Aliasing、Color Grading、Depth of Field等。Post-Processing Stack是一个模块化系统，可以按需启用不同的效果，并允许开发者以链式方式组合效果

7. CommandBuffer和Compute Shader (计算着色器)的结合
除了用于传统渲染指令，CommandBuffer在Unity中还可以与Compute Shader结合，实现复杂的图像处理、物理计算和GPU模拟任务。Compute Shader主要用于执行并行计算任务，可以有效处理大量数据，如粒子系统、流体模拟等。

8. SRP Batcher
SRP Batcher是Unity引入的一项技术，用于在Scriptable Render Pipeline中优化GPU绘制调用。它通过将不同材质的绘制指令合并，大幅提升了SRP的性能。SRP Batcher的作用在处理包含大量不同材质的场景时尤为显著。


# 04UE渲染架构的原则与方案
UE的采用了统一的核心渲染路径，即无论是延迟渲染还是前向渲染，都是在一套高度集成的架构下进行的。与Unity SRP的“从底层完全可编程”的设计理念形成了对比。避免了类似Unity的多套完全独立管线，而是在同一套架构下进行不同渲染路径的选择与切换。这让开发者可以基于项目需求进行调整，而不需要在多个架构之间迁移​。

与Unity相比，

基于物理的渲染（PBR）体系与先进的动态光照和GI（全局光照）系统。
内置了电影级别的后处理效果，如深度景深、运动模糊和镜头光晕。
UE5进一步提升了渲染架构，Nanite提供了虚拟几何体技术，Lumen则是动态全局光照系统。

## 多线程
UE渲染架构的多线程支持，引入了游戏线程、渲染线程、RHI线程。渲染线程与游戏线程分离确保在处理复杂场景时，渲染可以最大限度地利用硬件资源而不被游戏逻辑阻塞。
- 游戏线程（Game Thread）
	- 在每一帧，游戏线程会生成渲染所需的场景数据，如物体的位置、动画状态等。然后将数据打包并发送给渲染线程。使用`EnqueueRenderCommand`将渲染指令加入渲染线程的队列。
- 渲染线程（Rendering Thread）
    - 渲染线程负责决定哪些物体需要渲染、如何渲染。渲染线程接收来自游戏线程的数据，在适当时机从队列中取出这些指令，并将其转换为渲染指令 (FRenderCommand) 并将其添加到`Command List`中。这些指令是平台无关的。渲染线程在处理过程中会将指令缓存到Command List中，以提高执行效率。多个渲染任务可以通过批处理和缓存机制减少开销。
- RHI线程（RHI Thread）
	- RHI（Render Hardware Interface）会执行和转换渲染线程的Command List成为指定图形API的调用，提交GPU渲染。

在游戏线程，场景中的对象通过UPrimitiveComponent进行描述，当被提交到渲染线程时会生成FPrimitiveSceneProxy对象，作为镜像副本。
- [ ] 镜像好处有哪些

在传统渲染管线中，每一帧都需要为每个物体生成新的渲染指令。UE4.22引入了 FMeshDrawCommand作为渲染指令的抽象，通过将绘制指令与具体的渲染状态、资源绑定等独立开来，使得命令可以缓存并在后续帧中复用。Static Mesh 的FMeshDrawCommand在场景加载时生成并缓存，而动态对象则需要每一帧都会更新和生成。
- [ ] FMeshDrawCommand 包含哪些信息，如何复用

FMeshBatch是将FMeshDrawCommand与FPrimitiveSceneProxy解耦的，使得具体的Pass对FPrimitiveSceneProxy透明。FMeshBatch通过（FPrimitiveSceneProxy::DrawStaticElements）和（FPrimitiveSceneProxy::GetDynamicMeshElements）生成，对应了上面的静态和动态。然后，FMeshPassProcessor:: AddMeshBatch() 会根据渲染通道的需求(指定的shader、排序、剔除模式等)生成 FMeshDrawCommand。这些命令会被关联到相应的渲染管线阶段，如 Base Pass、Depth Pass、Shadow Pass 等。每个渲染通道（如 Base Pass、Depth Pass、Shadow Pass 等）都有一个相应的 FMeshPassProcessor，该类负责处理与该通道相关的所有 FMeshBatch，并生成最终的渲染命令。FMeshPassProcessor 会根据物体的特性（如是否需要写入深度缓冲、是否透明等）将 FMeshBatch 归类到不同的渲染通道。

执行这个pass的时候，我们只需要提交这个命令列表就好了。

所有的Pass都继承于FMeshPassProcessor，并且实现他的AddMeshBatch()函数。AddMeshBatch()就为这个pass添加MeshBatch，并将他转换成对应的FMeshDrawCommand



MeshBatch包含了具体pass确定最终着色器绑定和渲染状态所需的所有内容，并提交给渲染管线执行。如存储顶点相关数据的 FVertexFactory 以及材质渲染需要的 FMaterialRenderProxy 等，FMeshBatch可以在多个不同的Pass中复用，例如DepthPass和BasePass。不同的渲染通道可以复用相同的网格数据，而不必为每个渲染任务重新构建数据。



根据具体需求，渲染通道可分为标准通道、手动通道和动态绘制通道。标准通道（如深度通道、基通道等）可以进行命令缓存和并行处理，而动态通道适用于不需要高性能优化的场景，如编辑器中的实时预览。


FMeshPassProcessor将其由FMeshBatch对象转成一个或多个FMeshDrawCommand。例如，在动态阴影渲染中，该函数会根据每个灯光源、相机视角等参数生成不同的渲染批次。

每个FPrimitiveSceneProxy都会生成一个或多个 Mesh Draw Commands。

会根据渲染Pass（如Base Pass、Shadow Pass）进行分类，并在每个Pass中按需调用。

FMeshDrawCommand是一个完全无状态的绘制描述，存储了RHI需要知道关于网格体绘制的所有信息(使用的shader、资源绑定、绘制调用的参数)。最后我们只需要将FMeshDrawCommand提交(通过SubmitMeshDrawCommands())，UE就会帮我们做后续的内容(转换到RHI命令等等...)。

FMeshDrawCommand 将与渲染相关的所有信息封装为一个独立的对象，包括：
顶点工厂（Vertex Factory）：定义了如何从顶点缓冲区中获取数据。
材质（Material）：包含了渲染物体所需的着色器和渲染状态。
绘制状态（Draw State）：包括深度测试、混合模式等 GPU 状态设置。
渲染资源（Render Resources）：如顶点缓冲、索引缓冲等。

流程解析：
命令生成：
命令缓存：静态对象的命令在生成后会被缓存，以减少后续帧的重建成本。这个缓存机制大大降低了 Draw Call 的数量，提高了性能。
并行执行：在渲染阶段，这些 FMeshDrawCommand 会通过多线程的方式并行处理，利用 GPU 的并行能力加速渲染。

3. FMeshDrawCommand 的关键结构
FMeshDrawCommand 主要包括以下几个关键部分：

FRHIVertexInputState：定义了顶点格式和输入布局。
FRHIPipelineState：包含了着色器和渲染状态（如深度、混合设置等）。
FShaderBindingState：用于绑定 GPU 着色器所需的资源，如纹理、常量缓冲等。
FMeshDrawCommandPrimitiveIdInfo：处理物体的唯一 ID，用于支持实例化和复杂的渲染效果。



FMeshBatch 也是网格绘制处理器 FMeshPassProcessor 及处理过程中的重要元素，存储在 FPrimitiveSceneInfo::StaticMeshes 中。
特定的通道网格体处理器派生自"FMeshPassProcessor"基类，负责将"FMeshBatch"转换为用于给定通道的网格体绘制命令（FMeshDrawCommand） 。这是最终的绘制筛选发生的地方，会选择适当的着色器并收集着色器绑定。根据通道作用，有多种子类实现。在需要实现自定义的 MeshPass 的时候，可以创建对应的 FMeshPassProcessor （见“基于 MeshPass 的模型外扩型 UE4 描边方案与实现总结”）。


FMeshDrawCommand完整地描述了一个Pass Draw Call的所有状态和数据，如shader绑定、顶点数据、索引数据、PSO缓存等。






核心渲染流程在渲染线程中执行。其中，核心类是`FSceneRenderer`。每帧都会被创建，封装帧间临时数据。FSceneRenderer 对当前的场景视图 FScene 进行渲染。FScene 中保存有场景中所有需要渲染的物体的 FPrimitiveSceneInfo 。
- **FSceneRenderer**：负责调度和执行一系列Pass，是UE中渲染流程的真正实现。不同的渲染器都继承自该类，封装了具体的渲染流程，支持如延迟渲染、前向渲染等不同的渲染管线

分别代表PC和移动端的默认渲染器。

其中，`FDeferredShadingSceneRenderer`是最关键的，是UE默认的，实现了延迟渲染。
- **FMobileSceneRenderer**: 针对移动平台进行优化，专注于性能和功耗平衡，使用简化的渲染路径和特定的优化手段。
Forward Rendering is used primarily for VR and other performance-critical scenarios.

![[Pasted image 20240823002115.png]]

网格体渲染从FPrimitiveSceneProxy（图元场景代理）开始，将FMeshBatch提交给渲染器


渲染器会遍历场景的所有经过了可见性测试的PrimitiveSceneProxy对象，利用其接口收集不同的FMeshBatch，加入渲染队列中，所以我们自定义自己的渲染数据类型只需要继承FPrimitiveSceneProxy创建FMeshBatch就可以。





1. InitView() 的作用
InitView() 会根据当前帧的视图（视角、光源等）初始化所有需要渲染的对象。具体来说，InitView() 主要完成以下任务：

视图相关数据的初始化：包括视图矩阵、投影矩阵、场景的可见性信息等。这些信息决定了哪些对象在当前视角下是可见的，哪些需要被剔除。
可见性剔除：在此阶段，基于场景的空间分割结构（如八叉树、BVH 等），引擎会剔除视图范围外或被遮挡的物体，从而减少渲染开销。

InitView() 的结果直接影响后续的渲染任务分配和命令生成，它为每个视图确定了需要处理的对象及其相关信息。


渲染命令生成：在处理每个批次时，FMeshPassProcessor 会根据视图、材质和几何信息生成 FMeshDrawCommand，这些命令会被加入渲染任务列表，在后续阶段被执行。



1. Mesh Draw Commands
Mesh Draw Commands 这些命令由 FMeshPassProcessor 处理并最终提交给渲染管线。这些命令的设计使得相似的绘制任务可以批量处理，减少 CPU 和 GPU 之间的开销​ (CNBlogs)​ (Dream Fields)。

Mesh Draw Commands 是具体的绘制命令，包含每个对象的渲染信息。
Command List 是这些绘制命令的集合，负责管理和提交所有渲染指令。
Command List 在整个渲染流程中起到组织和优化的作用，是 RHI 与 GPU 之间的桥梁。

2. Command List
Command List 是渲染管线中的一个更高层次的概念，它是用来组织和管理 Mesh Draw Commands 的容器。FRHICommandList 是其中的核心类，负责记录和提交所有绘制指令。Command List 可以包含多个 Mesh Draw Commands，并将它们按照正确的顺序提交给 GPU 执行。它是 RHI 层与底层图形 API 交互的桥梁。

3. 关系与工作流程
在渲染过程中，Mesh Draw Commands 先由渲染器生成，经过剔除、排序等处理后，最终存储在 Command List 中。渲染线程会将这些 Command List 传递给 RHI 层，由 RHI 层负责提交给 GPU 进行实际绘制。通过这种分层结构，UE 可以灵活组织和优化渲染指令，实现高效的批处理和资源管理​ (CNBlogs)​ (Qiita)。















源码解析
cpp
复制代码
void AddMeshBatch(
    const FMeshBatch& MeshBatch, 
    uint64 BatchElementMask, 
    const FPrimitiveSceneProxy* PrimitiveSceneProxy
);
MeshBatch：要渲染的物体批次，包含了顶点数据、材质信息等。
BatchElementMask：一个位掩码，用于指定哪些 FMeshBatchElement 需要被渲染。
PrimitiveSceneProxy：与该批次相关联的场景代理，用于提供额外的渲染信息。






FDeferredShadingSceneRenderer 利用多个 Mesh Processors 来处理不同的渲染通道（如基础通道、透明通道等），并通过这些处理器生成最终的 Mesh Draw Commands。在确定可见物体后，使用 `FMeshProcessor` 将 `FMeshBatch` 转换为 `FMeshDrawCommand`，并按渲染Pass组织。每个Pass根据生成的命令列表，逐步执行渲染。命令列表在每个Pass中被高效遍历，并发送至GPU。
RHI生成的 Mesh Draw Commands 最终通过 RHI 进行提交。`FMeshProcessor` 类用于将场景中的 `FMeshBatch` 转换为 `FMeshDrawCommand`。不同的 `FMeshProcessor` 处理不同的渲染Pass，例如 `FBasePassMeshProcessor` 处理基础几何渲染，`FShadowDepthPassMeshProcessor` 处理阴影渲染。每个 `FMeshProcessor` 会基于当前渲染Pass的需求进行过滤和排序，并生成合适的绘制命令。




FScene 是整个场景的抽象表示，负责存储场景中的所有可渲染数据，是全局管理类。FPrimitiveSceneProxy 是具体对象的渲染代理，被FScene管理和调度。



FViewInfo 表示从特定视角（相机、玩家视角等）观察场景时的渲染数据。每个FViewInfo包含视锥、投影矩阵、可见性信息等，并且会基于这些信息决定哪些FPrimitiveSceneProxy需要被渲染。渲染过程会遍历场景中的FPrimitiveSceneProxy，并生成相应的FMeshBatch用于具体的绘制操作​ 。

FMeshBatch 是实际用于渲染的指令集，由FPrimitiveSceneProxy在当前视图中生成并被FViewInfo调度执行。

在渲染阶段，FViewInfo 确定可见对象，并从对应的FPrimitiveSceneProxy中获取数据，生成FMeshBatch，准备绘制指令。
最终，FMeshBatch被提交到渲染管线，完成实际的绘制操作。






## 延迟渲染管线
- **FDeferredShadingSceneRenderer**：是UE渲染管线的核心类，通过一系列的Pass实现了延迟渲染。
	- 渲染流程的核心控制：每帧渲染调用`Render()`来执行整个延迟渲染过程。按照特定顺序进行渲染，逐步生成G-buffer、光照计算以及后处理等。

其完整的过程包括：
1. 初始化视图，执行可见性判定（包括视锥体剔除、遮挡剔除）和光源设置。其主要步骤包括：
	- `PreVisibilityFrameSetup()`：视图的预处理，初始化一些必要的资源。
	- `ComputeViewVisibility()`：执行视锥体剔除、遮挡剔除，并将场景中可见的元素进行标记和分类。
1. Pre-Z Pass：提前渲染场景中的深度信息，写入不透明物体的深度值，减少后续渲染阶段的计算开销。
2. Base Pass：渲染场景中的所有不透明几何体，填充G-buffer。G-buffer存储了场景中每个像素的几何信息（法线、颜色、材质属性等）。这个阶段的输出是供后续光照计算使用的​。
3. Lighting Pass：使用G-Buffer中的数据进行光照计算，处理场景中所有的光源。支持各种光照模型，如PBR（物理基渲染）和传统Blinn-Phong模型。具体实现包括直接光、间接光和反射等。
4. Shadow Pass：生成阴影图，用于计算阴影遮挡。包括静态阴影、动态阴影、区域阴影等。UE4支持多种阴影技术，如PCF（Percentage Closer Filtering）、Cascaded Shadow Maps等。
5. 透明物体渲染：半透明物体不能使用传统的深度缓冲优化，因此需要在此阶段进行专门处理
6. Reflection Pass：处理反射效果，使用屏幕空间反射（SSR）或立方体贴图进行环境反射渲染。UE5中还引入了更先进的Lumen系统进行全局光照与反射的计算。
7. Ambient Occlusion Pass：通常采用屏幕空间环境光遮蔽（SSAO）算法。
8. Post-Processing Pass：处理包括色调映射、抗锯齿、景深、动态模糊、镜头光晕等后期效果。这一步通常是最后执行的，直接影响最终输出的画面质量。
9. **FinalImageComposition**： 最后，将各个通道的数据组合并输出最终图像。这里包括合并各种后处理效果、合成光照结果等，最终得到需要呈现的画面​

在所有渲染步骤完成后，FDeferredShadingSceneRenderer将渲染命令提交给RHI。

`FDeferredShadingSceneRenderer` 通过遍历 `FScene` 中的所有可见物体，提取出需要参与渲染的几何数据。这些数据包括：


具体而言，`FDeferredShadingSceneRenderer` 在执行 `InitViews` 阶段时，会对 Nanite 数据进行处理，将其与传统的几何体数据一同进行可见性剔除和绘制命令生成。anite 的几何体在进行可见性计算和绘制时，由 Nanite 自身的渲染管线处理，但在最终阶段，还是会通过 `FDeferredShadingSceneRenderer` 的光照计算和后处理步骤来完成整体渲染。
在实际渲染过程中，`FDeferredShadingSceneRenderer` 会调用 Lumen 的模块来处理全局光照的计算，尤其是在复杂场景中处理间接光、反射和环境光照的动态变化。

## RHI
渲染管线的各个Pass生成的渲染指令会通过这些接口发送到硬件。
- **FRHICommandList**：这是UE与底层图形API交互的主要接口。所有的渲染指令都会通过`FRHICommandList`发送到硬件。这些命令包括绘制调用、资源绑定、状态设置等。其主要作用包括：该类是渲染指令的核心调度器，负责批量管理和提交所有的渲染命令，如绘制调用、资源状态切换等。
	- 命令缓冲区：FRHICommandList 充当命令的缓冲区，在一帧中累积所有渲染指令，并最终在适当的时机将它们提交给GPU。渲染指令可以被批量处理，从而提高性能
	- 多线程支持：它支持在多个线程上生成渲染命令，这使得渲染任务能够高效并行处理，最大化利用硬件资源。
	- 资源过渡管理：FRHICommandList 还管理资源状态的转换（如从读到写的转换），确保资源在不同阶段被正确使用。

- **FRHIResource**：代表渲染资源的抽象，如纹理、缓冲区等。它们被封装在这一层中，以确保跨平台一致性。FRHIResource 是所有RH资源的基类，包括纹理、缓冲区、渲染目标等。其主要职责包括：
	- 生命周期管理：FRHIResource 负责管理资源的创建、引用计数和释放，确保资源在正确的时间被分配和销毁。
	- 跨平台抽象。

- 将各种顶点、索引Buffer统一成了FRHIBuffer

## 扩展
虽然UE的渲染管线不像Unity SRP那样允许开发者从底层完全自定义渲染流程，但它依然通过插件系统和源码扩展，自定义渲染管线。

插件和扩展：虽然UE的渲染路径相对固定，但通过插件和定制模块，开发者可以在UE的渲染架构上进行个性化扩展，添加自定义的渲染效果或优化方案。

- **渲染管线扩展**：开发者可以通过继承`FSceneRenderer`实现自定义的渲染管线。并实现他的Render()函数。

- **Custom Render Passes**：通过自定义渲染通道，在默认的渲染流程中插入额外的渲染逻辑。比如特效、屏幕空间效果或调试工具。关键点包括：
	- 可以在所有后处理效果之前插入一个自定义Pass，用于计算额外的屏幕空间效果。
	- 全局Shader与自定义绘制：通过使用全局Shader和低级渲染接口（如FRHICommandList），在自定义Pass中实现复杂的效果。
	- 引擎为自定义渲染通道提供了灵活的API支持，开发者可以通过继承或重写现有的渲染类，插入自定义逻辑。具体实现方式通常包括注册新的渲染通道，并在渲染流程中动态调用这些通道​。


插件与模块化扩展：通过插件机制，开发者可以为UE添加自定义渲染功能。UE5中的许多新功能（如Nanite、Lumen）都是以模块形式实现的，这使得功能开发和迭代变得更加独立和灵活。
自定义Shader与后处理管线：开发者可以通过继承和扩展现有的Shader和后处理框架，实现特定需求的视觉效果。后处理管线的灵活性使得开发者可以在现有渲染流程中插入自定义效果，例如特殊的色调映射、屏幕空间反射等。


- **自定义渲染路径（Custom Rendering Path）**：虽然不像Unity的SRP那样模块化，但UE支持通过修改引擎源码或使用渲染插件自定义渲染路径。



渲染队列（Render Queue）与命令列表（Command List）：UE的渲染架构中，所有渲染操作都是通过命令列表管理的。开发者可以在渲染过程中自定义命令，将特定任务添加到渲染队列中。这种方式为实现定制化渲染路径提供了灵活性。

引擎源码修改与插件扩展
引擎源码修改：对于需要深度定制的项目，UE的开源特性允许开发者直接修改引擎源码，例如创建新的渲染路径或自定义G-Buffer结构。这种方式在一些高度优化的项目中非常常见，特别是当默认的渲染管线无法满足特殊需求时。

插件扩展：UE的插件系统允许通过模块化的方式添加自定义渲染功能。开发者可以创建独立的渲染模块，插入到引擎的渲染管线中。例如，一些光照插件或渲染优化插件就是通过这种方式集成的。


为了模型合批、减少DrawCall等渲染优化，增加了动态和静态渲染路径，增加FMeshPassProcessor、FMeshBatch、FMeshDrawCommand等概念

为了适应和充分利用Vulkan、DirectX12等这种新型轻量级现代图形API，UE还在4.22引入了RDG（渲染依赖图表）





```c++
void FDeferredShadingSceneRenderer::Render(FRHICommandListImmediate& RHICmdList) {
    // 1. 场景设置
    PrepareView(RHICmdList);

    // Step 2: Shadow Maps and Light Setup
    RenderShadowMaps(RHICmdList);
    SetupLights(RHICmdList);

    // Step 3: Begin Scene Rendering
    BeginRenderingScene(RHICmdList);

    // Step 4: Render Base Pass (geometry, opaque objects)
    RenderBasePass(RHICmdList);

    // Step 5: Render Deferred Lighting (lighting calculations)
    RenderDeferredLighting(RHICmdList);

    // Step 6: Render Translucent Objects
    RenderTranslucency(RHICmdList);

    // Step 7: Post-Processing
    RenderPostProcessing(RHICmdList);

    // Step 8: Final Composition and Present
    PresentFrame(RHICmdList);
}

// Scene Setup: Prepares views and culling
void FDeferredShadingSceneRenderer::PrepareView(FRHICommandListImmediate& RHICmdList) {
    for (FViewInfo& View : Views) {
        // Calculate culling parameters and perform frustum culling
        View.InitCulling();
    }
}

// Shadow Maps and Lighting Setup
void FDeferredShadingSceneRenderer::RenderShadowMaps(FRHICommandListImmediate& RHICmdList) {
    // Render shadow maps for directional, point, and spot lights
    for (FLightSceneInfo& Light : Scene->Lights) {
        if (Light.NeedsShadowMap()) {
            RenderShadowMapForLight(RHICmdList, Light);
        }
    }
}

// Base Pass Rendering: Render opaque objects and basic materials
void FDeferredShadingSceneRenderer::RenderBasePass(FRHICommandListImmediate& RHICmdList) {
    for (FPrimitiveSceneInfo& Primitive : Scene->Primitives) {
        if (Primitive.IsOpaque()) {
            RenderPrimitive(RHICmdList, Primitive);
        }
    }
}

// Deferred Lighting: Calculate lighting based on G-buffer
void FDeferredShadingSceneRenderer::RenderDeferredLighting(FRHICommandListImmediate& RHICmdList) {
    for (FLightSceneInfo& Light : Scene->Lights) {
        CalculateLighting(RHICmdList, Light);
    }
}

// Translucency Rendering
void FDeferredShadingSceneRenderer::RenderTranslucency(FRHICommandListImmediate& RHICmdList) {
    for (FPrimitiveSceneInfo& Primitive : Scene->Primitives) {
        if (Primitive.IsTranslucent()) {
            RenderPrimitive(RHICmdList, Primitive);
        }
    }
}

// Post-Processing: Apply post effects (e.g., bloom, tone mapping)
void FDeferredShadingSceneRenderer::RenderPostProcessing(FRHICommandListImmediate& RHICmdList) {
    ApplyBloom(RHICmdList);
    ApplyToneMapping(RHICmdList);
}

// Final Composition and Present Frame
void FDeferredShadingSceneRenderer::PresentFrame(FRHICommandListImmediate& RHICmdList) {
    // Composite the final image and present it to the screen
    RHICmdList.Submit();
}
```

FMeshDrawCommand: Encapsulates all rendering information needed for a single draw call, including mesh data, shaders, and render states.
Static and Dynamic Mesh Handling: UE separates static and dynamic objects to optimize rendering efficiency. Static meshes benefit from pre-computed draw commands, while dynamic meshes are handled on a per-frame basis.
Mesh Processors: Different rendering passes (e.g., depth pass, base pass) are managed by mesh processors. Each processor converts FMeshBatch data into optimized draw commands for a specific rendering pass​ (Epic Games Developer)​ (Epic Games Developer).
Deferred and Forward Rendering:








1. 从即时模式到保留模式的转变
过去的渲染管线采用即时模式（Immediate Mode），每帧都会重新构建可见对象的绘制列表，这会导致大量的计算开销。在新架构中，UE转向保留模式（Retained Mode），绘制命令被缓存并在多帧之间重复使用。这种方式显著降低了CPU的开销，尤其在复杂场景中表现尤为明显​ (Epic Games Developer)​ (Unreal Engine)。

2. Mesh Draw Commands的引入
新的渲染管线引入了FMeshDrawCommand，它封装了所有与渲染相关的信息，包括网格数据、着色器绑定和渲染状态。通过将这些信息预先缓存，渲染命令可以在每帧中快速调用，大大提高了渲染效率。

3. 优化的静态与动态绘制列表
在旧架构中，静态网格和动态网格绘制列表是分离的，而在新的架构中，这些列表被合并，这不仅简化了渲染流程，还支持对静态和动态物体的统一排序和优化。这种改进提升了大规模场景的渲染性能，尤其在需要大量动态对象的场景中效果显著​ 。

4. 更灵活的Mesh Processor系统
传统的绘制策略被Mesh Processors取代，Mesh Processors负责将FMeshBatch转换为优化后的绘制命令。不同的绘制Pass（如深度Pass、基础Pass）都有各自的Mesh Processor，这使得不同渲染步骤间的优化和定制更加灵活。

5. 改进的Shader绑定和缓存机制
新管线将着色器参数集中管理，通过FMeshDrawSingleShaderBindings进行绑定和缓存。这不仅提高了渲染效率，还允许更多着色器实例的重用，减少了运行时的开销​。

6. 支持GPU Scene的实现
新的渲染管线引入了GPU Scene，这是一种结构化缓冲区，用于存储场景中所有原始数据。通过让着色器访问这个缓冲区，可以显著减少内存访问和数据传输的成本，提高整体渲染性能​


# 05对比与讨论
Unity采用的是更模块化、轻量化的架构，强调灵活性和可扩展性，让开发者通过C#轻松构建和调整渲染管线，适应各种项目需求。SRP完全通过C#脚本进行控制，开发者可以自定义管线的各个步骤，包括物体剔除、渲染顺序、后处理等。SRP允许开发者在移动设备和低性能硬件上实现可接受的图形效果。

Unreal Engine采用了高度集成的架构，通过C++，同时通过现代渲染技术如Nanite和Lumen增强图形表现。 UE的渲染管线通过高度优化的C++代码实现，提供了多个渲染路径（如前向渲染和延迟渲染）。每个阶段都可以独立调整，开发者可深入到渲染流程的任意部分进行优化或扩展。UE的渲染模块（如Renderer Module）控制整个渲染流程，结合引擎的其他部分（如材质系统和光照系统），实现高度整合的图形渲染。Nanite的虚拟化几何系统使其可以渲染数十亿多边形的场景，而Lumen提供了实时全局光照和动态反射的能力。这些技术通过底层C++深度集成，结合UE的Render Graph实现了高效的渲染优化。UE还支持复杂的后处理链、物理光照计算和高级材质系统，使其在视觉效果上领先。

简化开发流程，入门门槛相对较低，C#脚本语言使得开发者能够快速上手，并通过Unity的丰富生态系统获取支持。其SRP提供了良好的开发灵活性，同时保持了相对简单的使用体验。
Unreal Engine: Unreal由于其高复杂度和强大的功能，学习曲线相对陡峭。C++的使用增加了灵活性和性能，但也对开发者的技术水平提出了更高要求。尽管如此，UE提供了丰富的文档和社区支持，帮助开发者掌握其复杂的渲染体系。


Unity和UE可能会如何继续调整各自的渲染架构设计。

实时光线追踪、混合渲染、云渲染等新兴技术如何影响UE和Unity的渲染架构。

最后一个部分可以总结一下当前技术趋势（如实时光线追踪、混合渲染等）对Unity和UE渲染架构的潜在影响，并探讨这两款引擎在未来可能的演进方向。这不仅能够呼应文章开头的行业共性问题，还能为文章提供更具深度的结论。











Custom Render Passes：UE允许开发者自定义渲染通道，在标准渲染流程中插入自定义逻辑，例如特殊的视觉效果或调试工具。通过实现自定义的全局Shader并扩展渲染器，开发者可以灵活定制渲染管线​

- 视图与场景的结合：在每一帧中，FSceneRenderer 会结合多个 FView 实例和一个 FScene，决定如何渲染场景中的每个对象。





关键的数据结构如`FPrimitiveSceneProxy`（表示场景中的对象）和`FMeshBatch`（包含绘制信息）

场景中的所有对象和光源都会被组织成一个Scene Graph。渲染流程中，会根据视图的可见性计算哪些对象需要被渲染，并生成对应的绘制指令。在UE4.22之后，渲染架构引入了`FMeshDrawCommand`和`FMeshPassProcessor`等优化机制，通过缓存绘制指令减少重复计算，提升渲染效率​





















1. 输入资源与资源管理
FRHIResource：FRHIResource 是所有图形资源的基类，包括纹理、缓冲区等。这些输入资源由场景（FScene）和视图（FView）进行组织和管理。场景包含所有的可渲染对象和光源，而视图则负责描述如何观察场景，包括摄像机位置、投影矩阵等信息。

2. 渲染处理与优化



- 高层控制
负责渲染流程的总体调度和管理，包括场景管理、帧生成以及渲染器调度。主要由`FScene`, `FView`, `FSceneRenderer`等核心类构成。
- **FScene**：负责管理和存储场景中的数据（对象、光源、材质等），提供渲染所需的基础信息。基本功能包括：
	- 场景数据的组织与管理：FScene维护场景中所有可渲染对象的状态，并提供接口用于查询和访问这些对象。
	- 渲染线程与游戏线程的同步：FScene 在游戏线程中被更新，但渲染线程需要读取场景数据，因此它也处理两者之间的同步工作。
	- 此外，FScene 并不仅仅是一个数据容器，它还包含一些与场景管理相关的逻辑，例如灯光信息的管理和对象的可见性计算​。

- **FViewInfo**：管理摄像机的视图矩阵、投影矩阵、剔除信息等。
	- 视图设置与状态：FView 包含了视角、屏幕分辨率、场景可见性等数据，这些信息会影响场景的渲染方式。
	- 多视图会有多个 FView 实例，每个实例对应一个独立的视图。

剔除后的可见物体信息被存储在 `FPrimitiveViewRelevance` 中，该对象包含了关于每个物体是否参与特定渲染Pass（如Base Pass、Shadow Pass等）的标志。



# 参考文献
- 剖析虚幻渲染体系（03）- 渲染机制  https://www.cnblogs.com/timlly/p/14588598.html#31-%E6%9C%AC%E7%AF%87%E6%A6%82%E8%BF%B0%E5%92%8C%E5%9F%BA%E7%A1%80











渲染管线设计原则：
![[Pasted image 20240819103548.png]]

Build-in 管线
![[Pasted image 20240819104134.png]]
![[Pasted image 20240819104207.png]] 

Deferred Rendering：第一个pass填充Gbuffer，第二个pass执行Lighting
![[Pasted image 20240819215612.png]]

Unity提供了宏来帮助Mobile进行读取Buffer

没看懂
![[Pasted image 20240819220228.png]]

没看懂
![[Pasted image 20240819220954.png]]


[SIGGRAPH 2021 REAC: Unity Rendering Architecture (youtube.com)](https://www.youtube.com/watch?v=6LzcXPIWUbc)
[Unity Scriptable Render Pipeline（一） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/460780649)
[SIGGRAPH 2021 REAC: Unity Rendering Architecture - YouTube](https://www.youtube.com/watch?v=6LzcXPIWUbc)
[现代图形引擎入门指南（十五）— 渲染架构 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/659774241)











[UE管线图解 - 渲染 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/640554450)
[UE渲染源码剖析 - Heskey0 - 博客园 (cnblogs.com)](https://www.cnblogs.com/Heskey0/p/16182731.html)
[虚幻引擎UE渲染框架 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/484960867)
[Unreal 渲染管线原理机制源码剖析 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/641367884)
[Re：从零开始的UE渲染学习-1开篇预览 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/680266148)
[UE5渲染管线概览 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/508372052)
[UE5中的卡通渲染——自定义描边Pass - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/597864516)
[Pushing Next-Gen Real-Time Technology in Marvel 1943: Rise of Hydra | GDC 2024 (youtube.com)](https://www.youtube.com/watch?v=PRc_Vy-W0yw)



[Begin Play | Rendering | Epic Developer Community (epicgames.com)](https://dev.epicgames.com/community/learning/tutorials/vyZ1/unreal-engine-begin-play-rendering)

[Optimizing UE5: Rethinking Performance Paradigms for High-Quality Visuals - Part 1: Nanite and Lumen | Unreal Fest 2023 | Epic Developer Community (epicgames.com)](https://dev.epicgames.com/community/learning/talks-and-demos/Vpv2/unreal-engine-optimizing-ue5-rethinking-performance-paradigms-for-high-quality-visuals-part-1-nanite-and-lumen-unreal-fest-2023)

[Optimizing UE5: Rethinking Performance Paradigms for High-Quality Visuals - Pt 2: Supporting Systems | Unreal Fest 2023 | Epic Developer Community (epicgames.com)](https://dev.epicgames.com/community/learning/talks-and-demos/VlO2/unreal-engine-optimizing-ue5-rethinking-performance-paradigms-for-high-quality-visuals-pt-2-supporting-systems-unreal-fest-2023)

[Designing Visuals, Rendering, and Graphics with Unreal Engine | Unreal Engine 5.4 Documentation | Epic Developer Community (epicgames.com)](https://dev.epicgames.com/documentation/en-us/unreal-engine/designing-visuals-rendering-and-graphics-with-unreal-engine)